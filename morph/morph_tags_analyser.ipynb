{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3b5cd-cff9-4ff2-b326-c0021bac5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sequence_unique(string):\n",
    "    dct = dict()\n",
    "    string = string.split()\n",
    "    cur_ind = 0\n",
    "    while cur_ind < len(string):\n",
    "        if string[cur_ind] in dct.keys():\n",
    "            raise ValueError\n",
    "        dct[string[cur_ind]] = int(string[cur_ind + 1])\n",
    "        cur_ind += 2\n",
    "    return dct\n",
    "\n",
    "class DatasetLine:\n",
    "    def __init__(self, line_list_csv):\n",
    "        self.CLIENT_ID, self.RETRO_DT, self.tokens, self.DEF, self.urls_hashed = line_list_csv\n",
    "\n",
    "        self.tokens = parse_sequence_unique(line_list_csv[2])\n",
    "        self.DEF = int(self.DEF)\n",
    "        self.urls_hashed = parse_sequence_unique(line_list_csv[4])\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dataset_parser_iterator(name_string, logging = False):\n",
    "    with open(name_string, 'r') as csv_file:\n",
    "        line_count = 0\n",
    "        for row in csv_file:\n",
    "            row_l = row.split('\\t')\n",
    "            if line_count == 0:\n",
    "                if logging:\n",
    "                    print(f'Column names are {\", \".join(row_l)}')\n",
    "                line_count += 1\n",
    "            else:\n",
    "                yield row, DatasetLine(row_l)\n",
    "                line_count += 1\n",
    "        if logging:\n",
    "            print(f'Processed {line_count} lines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a7b90-8905-4f08-a503-0f1cc5c1d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_false = open(\"train_shit.csv\", 'w')\n",
    "f_true = open(\"train_clear.csv\", 'w')\n",
    "\n",
    "begin = open(\"train.csv\").readline()\n",
    "f_false.write(begin)\n",
    "f_true.write(begin)\n",
    "\n",
    "for row_text, DLine in dataset_parser_iterator(\"train.csv\"):\n",
    "    if DLine.urls_hashed.keys() and DLine.tokens.keys():\n",
    "        f_true.write(row_text)\n",
    "    else:\n",
    "        f_false.write(row_text)\n",
    "\n",
    "f_false.close()\n",
    "f_true.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d103e6-c47f-404d-9b5a-6cbe04d2833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from transliterate import translit\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer(lang='ru')\n",
    "\n",
    "def get_normal_form(word):\n",
    "    return morph.parse(translit(word, 'ru'))[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583ad28-b5a5-4517-bf0d-29ed77a3c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_all_items = dict() # сумма тайтлов за все время\n",
    "\n",
    "for row_text, DLine in dataset_parser_iterator(\"train_clear.csv\"):\n",
    "    for item in DLine.tokens.items():\n",
    "        key = get_normal_form(item[0])\n",
    "        counter_all_items[key] = counter_all_items.get(item[0], 0) + item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8461e4-9a04-40cb-9bba-6d1b4f68c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_all_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b966ec7-4170-47ee-a30d-c9bd89b5d3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_all_items = dict() # кол-во тайтлов за все время\n",
    "\n",
    "for row_text, DLine in dataset_parser_iterator(\"train_clear.csv\"):\n",
    "    for item in DLine.tokens.items():\n",
    "        key = get_normal_form(item[0])\n",
    "        amount_all_items[key] = amount_all_items.get(item[0], 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5665959-ca0a-4fb5-9e83-43816a6f927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"items_statistics_all_lines_initial_foem.csv\") as out_file:\n",
    "    out_file.write(sorted(counter_all_items.items(), key=lambda item: item[1], reverse=True).__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4d42e-8378-4bec-81a9-ecf0b66f8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"items_statistics_all_lines_initial_foem.csv\") as out_file:\n",
    "    out_file.write(sorted(amount_all_items.items(), key=lambda item: item[1], reverse=True).__repr__())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
